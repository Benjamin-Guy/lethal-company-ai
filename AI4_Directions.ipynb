{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import os\n",
    "import cv2 \n",
    "import keyboard\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps, ImageGrab\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io, color, measure, morphology\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import rotate\n",
    "import copy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread(r'training\\3.png')[75:835, 395:1426]\n",
    "# At the end is crop to monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item detection\n",
    "Scrap items appear to all appear at roughly the same shape, size, and colour. This suggests template matching as a solution. However, upon examining the training images, it was noted that each scrap item had the exact same colour albeit for a small difference observed in one case. This suggests that precise colour thresholding will be very effective at isolating the scrap items from the rest of the image. The steps for the item detection are as follows:\n",
    "\n",
    "- RGB colour threeshold applied to the image to identify scrap items.\n",
    "- Dilate segments of scrap items. This helps prevent map elements that sometimes break up the appearance of scrap as appearing as more than one scrap item when it is only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = cv2.imread(r'training\\3.png')[75:835, 395:1426]\n",
    "\n",
    "# Colour threshold for scrap items\n",
    "scrap_lower_bound = (1, 254, 172)\n",
    "scrap_upper_bound = (2, 255, 177)\n",
    "\n",
    "# Colour threshold the image\n",
    "color_mask = cv2.inRange(monitor, scrap_lower_bound, scrap_upper_bound)\n",
    "\n",
    "# Dilate segments\n",
    "kernel_size = (5, 5)\n",
    "kernel = np.ones(kernel_size, np.uint8)\n",
    "item_mask = cv2.dilate(color_mask, kernel, iterations=3)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Binary Mask', item_mask)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enemy detection\n",
    "Similar to scrap items, enemies all have the same shape and colour, but have differences in size. There are also issues with other objects appearing the same colour as the enemies on the monitor. This necessitates a requirement for more sophisticated methods of detection. Circular Hough Transforms were tried, but too difficult to implement. A simple solution was found by using morphological opening to filter out non-circular shaped objects that proved better than the circular hough transform. This will be used to improve the enemy detection method.\n",
    "\n",
    "- RGB colour threshold applied to the image to filter out noise and any objects not red.\n",
    "- Morphological opening (erode, then dilate) to remove non-circular segments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = cv2.imread(r'training\\17.png')[75:835, 395:1426]\n",
    "# 5, 8\n",
    "\n",
    "# Colour threshold for enemies\n",
    "enemy_lower_bound = (1, 1, 85)\n",
    "enemy_upper_bound = (25, 25, 255)\n",
    "\n",
    "# Colour threshold the image\n",
    "color_mask = cv2.inRange(monitor, enemy_lower_bound, enemy_upper_bound)\n",
    "\n",
    "# Morphological Opening\n",
    "kernel_size = (4, 4)\n",
    "kernel = np.ones(kernel_size, np.uint8)\n",
    "dilated_mask = cv2.erode(color_mask, kernel, iterations=2)\n",
    "enemy_mask = cv2.dilate(dilated_mask, kernel, iterations=3)\n",
    "\n",
    "cv2.imshow('Original Image', monitor)\n",
    "cv2.imshow('Binary Mask', enemy_mask)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player Angle Detection\n",
    "\n",
    "Simplify the method used to detect what direction the player is looking in, and return one of four simple directions: (front, behind, left, right). There were somoe difficulties here as the colour thresholding is not as effective. However, the cases where this become an issue are quite limited. The process for detecting the angle the player is looking in is as follows:\n",
    "\n",
    "- Crop the image to just the player.\n",
    "- Blue colour thresholding on the image to isolate the player.\n",
    "- Average a centroid for the segmented areas and calculate the angle based on the centre of the image to that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.14058270723698\n"
     ]
    }
   ],
   "source": [
    "def calculate_angle(binary_mask):\n",
    "    # Calculate the centroid of the white pixels in the binary mask\n",
    "    Y, X = np.where(binary_mask == 255)\n",
    "    centroid_x = np.mean(X)\n",
    "    centroid_y = np.mean(Y)\n",
    "\n",
    "    # Determine the center point of the image\n",
    "    image_center_x, image_center_y = binary_mask.shape[1] / 2, binary_mask.shape[0] / 2\n",
    "\n",
    "    # Calculate the angle to the centroid of the largest segment\n",
    "    delta_x = centroid_x - image_center_x\n",
    "    delta_y = image_center_y - centroid_y  # Image coordinates are top-left, so we invert the y-axis\n",
    "    angle_rad = math.atan2(delta_y, delta_x)  # Calculate angle in radians\n",
    "    # Adjust the angle so 0 degrees is 'up' and positive angles are clockwise\n",
    "    angle_deg = (90 - math.degrees(angle_rad)) % 360\n",
    "\n",
    "    return angle_deg\n",
    "\n",
    "monitor = cv2.imread(r'training\\16.png')[75:835, 395:1426]\n",
    "player = monitor[307:473, 453:619]\n",
    "\n",
    "# Colour thresholds for the player\n",
    "player_lower_bound = (90, 1, 1)\n",
    "player_upper_bound = (255, 200, 10)\n",
    "\n",
    "# Colour threshold the image\n",
    "color_mask = cv2.inRange(player, player_lower_bound, player_upper_bound)\n",
    "\n",
    "# Dilate to fill in any noise\n",
    "kernel_size = (5, 5)\n",
    "kernel = np.ones(kernel_size, np.uint8)\n",
    "player_mask = cv2.dilate(color_mask, kernel, iterations=3)\n",
    "\n",
    "angle = calculate_angle(player_mask)\n",
    "print(angle)\n",
    "\n",
    "cv2.imshow('Monitor', player_mask)\n",
    "cv2.imshow('Player', player)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supporting Functions\n",
    "Support functions such as converting a degree angle to a direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direction_from_angle(angle):\n",
    "    # Normalize the angle to the range [0, 360)\n",
    "    angle = angle % 360\n",
    "\n",
    "    # Determine the direction based on the angle range\n",
    "    if (angle >= 315 and angle < 360) or (angle >= 0 and angle < 45):\n",
    "        return 'front'\n",
    "    elif 45 <= angle < 135:\n",
    "        return 'right'\n",
    "    elif 135 <= angle < 225:\n",
    "        return 'behind'\n",
    "    else:  # 225 <= angle < 315\n",
    "        return 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_coords(image_mask):\n",
    "    contours, _ = cv2.findContours(image_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing All Together\n",
    "Now we "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
